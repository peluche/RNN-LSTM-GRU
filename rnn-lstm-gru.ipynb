{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN / LSTM / GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import requests\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "device = 'cuda' if t.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download alice in wonderland\n",
    "url = 'https://www.gutenberg.org/cache/epub/11/pg11.txt'\n",
    "book = requests.get(url).content\n",
    "book = book.decode('ascii', 'ignore')\n",
    "vocab = set(book)\n",
    "d_vocab = len(vocab)\n",
    "d_hidden = 100\n",
    "d_batch = 10000\n",
    "atoi = {a: i for i, a in enumerate(vocab)}\n",
    "itoa = {i: a for a, i in atoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6573, 25])\n"
     ]
    }
   ],
   "source": [
    "def to_dataloader(text, seq_len=25, batch_size=d_batch):\n",
    "    x = [text[i:i+seq_len] for i in range(0, len(text)-seq_len-1, seq_len)]\n",
    "    y = [text[i+1:i+seq_len+1] for i in range(0, len(text)-seq_len-1, seq_len)]\n",
    "    x = t.tensor([[atoi[a] for a in s] for s in x])\n",
    "    y = t.tensor([[atoi[a] for a in s] for s in y])\n",
    "    dataset = TensorDataset(x, y)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataloader = to_dataloader(book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks (RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, d_in=10, d_hidden=20, d_out=30):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Linear(d_in, d_hidden)\n",
    "        self.hidden = nn.Linear(d_hidden, d_hidden)\n",
    "        self.unembed = nn.Linear(d_hidden, d_out)\n",
    "\n",
    "    def forward(self, xs, memory=None, return_memory=False):\n",
    "        # xs: (batch, d_context, d_vocab)\n",
    "        batch, d_context, _ = xs.shape\n",
    "        outs = []\n",
    "        if memory is None: memory = t.zeros(batch, self.hidden.in_features, device=xs.device)\n",
    "        for i in range(d_context):\n",
    "            x = xs[:, i]\n",
    "            memory = F.tanh(self.embed(x) + self.hidden(memory))\n",
    "            outs.append(self.unembed(memory))\n",
    "        if return_memory:\n",
    "            return t.stack(outs, dim=1), memory\n",
    "        return t.stack(outs, dim=1)\n",
    "\n",
    "rnn = RNN(d_vocab, d_hidden, d_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@t.no_grad()\n",
    "def sample(model, text='A', d_sample=100):\n",
    "    model = model.to(device)\n",
    "    memory = t.zeros(1, model.hidden.in_features).to(device)\n",
    "    x = t.tensor([[atoi[c] for c in text]])\n",
    "    x = F.one_hot(x, num_classes=d_vocab).float().to(device)\n",
    "    while len(text) <= d_sample:\n",
    "        outs, memory = model(x, memory=memory, return_memory=True)\n",
    "        probs = outs[0, -1].softmax(dim=0)\n",
    "        next_sample = t.multinomial(probs, num_samples=1)\n",
    "        text += itoa[next_sample.item()]\n",
    "        x = F.one_hot(next_sample, num_classes=d_vocab).float().to(device)[:, None, :]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b997ea402a44fef88131e180e8584a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=4.4122\n",
      "ASntTexs1z!JC#O#dLnn'PkTtr77NB0H;[fXg64#'OIfGbtCc2#je):-xkDb.y/_,stP-5fjFpV!BIR2fS96q l_D)0,Xj0P.NwI?\n",
      "loss=3.3527\n",
      "loss=3.2293\n",
      "loss=3.2073\n",
      "loss=3.1836\n",
      "loss=3.1493\n",
      "loss=3.0961\n",
      "loss=3.0164\n",
      "loss=2.9224\n",
      "loss=2.8226\n",
      "loss=2.7290\n",
      "loss=2.6469\n",
      "loss=2.5771\n",
      "loss=2.5167\n",
      "loss=2.4629\n",
      "loss=2.4139\n",
      "loss=2.3692\n",
      "loss=2.3295\n",
      "loss=2.2943\n",
      "loss=2.2622\n",
      "loss=2.2327\n",
      "Aliter tains ghe ke she to f saicJ tc\n",
      "wotrehi, koaidi6g! Ihd terang of uthid tll_mtcouve m*se   he \n",
      "loss=2.2052\n",
      "loss=2.1795\n",
      "loss=2.1553\n",
      "loss=2.1327\n",
      "loss=2.1115\n",
      "loss=2.0915\n",
      "loss=2.0724\n",
      "loss=2.0544\n",
      "loss=2.0371\n",
      "loss=2.0206\n",
      "loss=2.0047\n",
      "loss=1.9894\n",
      "loss=1.9748\n",
      "loss=1.9606\n",
      "loss=1.9470\n",
      "loss=1.9338\n",
      "loss=1.9211\n",
      "loss=1.9088\n",
      "loss=1.8969\n",
      "loss=1.8853\n",
      "Alice: thead, all s\n",
      "vertur, wand rek to be werhar hirghny Fron coulbebedoiget, but ol the King if to\n"
     ]
    }
   ],
   "source": [
    "def train(model, dataloader, epochs=2001, d_vocab=d_vocab, opt=None, lr=3e-4):\n",
    "    model = model.to(device)\n",
    "    if opt is None:\n",
    "        opt = t.optim.Adam(model.parameters(), lr=lr)\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        for xs, ys in dataloader:\n",
    "            out = model(F.one_hot(xs, num_classes=d_vocab).float().to(device))\n",
    "            loss = F.cross_entropy(out.permute(0, 2, 1), ys.to(device))\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        if epoch % 50 == 0:\n",
    "            print(f'loss={loss.item():.4f}')\n",
    "        if epoch % 1000 == 0:\n",
    "            print(sample(model))\n",
    "        if epoch % 10000 == 0:\n",
    "            t.save(model.state_dict(), f'weights/rnn_{datetime.now().strftime(\"%Y-%m-%d_%Hh%M\")}.pt')\n",
    "\n",
    "train(rnn, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice soon the Gryphan?cas  be tuthous it low, said GU\n",
      "Tha boof jurs wore on phorda git. jad oo sher.\n",
      "\n",
      "Thes of\n",
      "herelird about aqlimnsee the  aimens corsaid ous meem.\n",
      "\n",
      "1PDoIm \n",
      " A CAtH\n",
      "AUNPREATI M NOR.HD IHH T61.ED3. OE LIN I R (HM HX Gut dbarg \n",
      "ffellferrved, iny_ fry. I\n",
      "dor  o  o pome g a deputseen all\n",
      "to dowence, all tare, and toite say, was unde to rowick orkint hes asave lotsus sheaver on, and was heswould, said thee southe\n",
      "foume.\n",
      "\n",
      "The piole hoandef, the laggion,\n",
      "and chouttongroon courd  to bes\n",
      "she tay thed not kinl \n",
      "\n",
      "yon tho kinll I dagant the leece sQuein, the  ho chiment it witht and heat inea nol, th thel nel saed to quetre fortanis hendes und it dawry hat she Lit\n",
      "the DokbigeMo\n",
      "\n",
      "Thene; in it has seadide betas sain nlermuth a? nat futthes the Micg.\n",
      "\n",
      "Why, sto hai kagying anverson ir was ple witn, thing hind the Creltintis whed in the Mack of eloop ofe undared of, it make theep, taitid waid\n",
      "on then the gedar tames eroughtabling, s outhea wouthing whet whele, Imbeig. Whe hergelo to goo to bututhe I rifewhon Alace was _ mant\n",
      "\n",
      "AlT_: ing that was with? sIm  ull whe was\n",
      "ploaydedever themuren the copy ir_; cerlablend.: Hat they: bat! Lat\n",
      "shiw, ablly queacl ig to ar\n",
      "Arice, and whet foutwalkr.\n",
      "\n",
      "Dont Gryphen veryed.\n",
      "\n",
      "Alice tadking Alice taided then chould botst enemsaiin, he chave\n",
      "tellend towh frat to but al at wos, Seaclla fot the dinco hezllltserous queinging tort felle har qtithi, hat it ftlitg of ase sading bolf do s out locker dionaid to groen ca ledntonteall wharg tlice ryoud ask! sto ecoushan oprwers af sotllew; sno th3 eremuld olt thea shel ave _yrtent otr apdo\n",
      "\n",
      "reself\n",
      "fracilis latishSunter) mumf you feat\n",
      "to\n",
      "ngnoutidgut, and llen ighl a dryot, abes_ she fal longo thes work-.osteded said ary and pomkeher you dnand to\n",
      "ont llitelf youg timy comastubet it lite, in o har expevangyom. I\n",
      "The couddre one wonkich, as uning she laray itwer she bo\n"
     ]
    }
   ],
   "source": [
    "print(sample(rnn, d_sample=2000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long Short-Term Memory (LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A\\nmEbZQqPp5?EewrPh%lKTu.HX$5U?2\\ruQ_9.7:0Of8(QZ ,fLRcvhJ/]00UJe6C,T.XHpqkS%k\\rWf]vuj\\r)/N55Q.830j[Gg5H1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LSTMCell(nn.Module):\n",
    "    def __init__(self, d_in, d_hidden):\n",
    "        super().__init__()\n",
    "        self.d_hidden = d_hidden\n",
    "        self.W_f = nn.Linear(d_in + d_hidden, d_hidden)  # forget gate\n",
    "        self.W_i = nn.Linear(d_in + d_hidden, d_hidden)  # input gate\n",
    "        self.W_c = nn.Linear(d_in + d_hidden, d_hidden)  # cell state update\n",
    "        self.W_o = nn.Linear(d_in + d_hidden, d_hidden)  # output gate\n",
    "\n",
    "    def forward(self, x, h_prev, c_prev):\n",
    "        x = t.cat((x, h_prev), dim=1)\n",
    "        # handle long-term memory `C`\n",
    "        f_gate = t.sigmoid(self.W_f(x))\n",
    "        i_gate = t.sigmoid(self.W_i(x))\n",
    "        c_update = t.tanh(self.W_c(x))\n",
    "        c_prev = f_gate * c_prev + i_gate * c_update\n",
    "        # handle short-term memory `h`\n",
    "        o_gate = t.sigmoid(self.W_o(x))\n",
    "        h_prev = o_gate * t.tanh(c_prev)\n",
    "        return h_prev, c_prev\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, d_in, d_hidden, d_out):\n",
    "        super().__init__()\n",
    "        self.d_hidden = d_hidden\n",
    "        self.lstm_cell = LSTMCell(d_in, d_hidden)\n",
    "        self.unembed = nn.Linear(d_hidden, d_out)\n",
    "\n",
    "    def forward(self, xs, h_prev=None, c_prev=None):\n",
    "        # xs: (batch, d_context, d_vocab)\n",
    "        batch, d_context, _ = xs.shape\n",
    "        outs = []\n",
    "        if h_prev is None: h_prev = t.zeros(batch, self.d_hidden, device=xs.device)\n",
    "        if c_prev is None: c_prev = t.zeros(batch, self.d_hidden, device=xs.device)\n",
    "        for i in range(d_context):\n",
    "            x = xs[:, i]\n",
    "            h_prev, c_prev = self.lstm_cell(x, h_prev, c_prev)\n",
    "            outs.append(self.unembed(h_prev))\n",
    "        return t.stack(outs, dim=1)\n",
    "\n",
    "    @t.no_grad()\n",
    "    def sample(self, seed='A', d_sample=100):\n",
    "        text = seed\n",
    "        x = F.one_hot(t.tensor([atoi[seed]]), num_classes=d_vocab).float().to(device)\n",
    "        h_prev = t.zeros(1, self.d_hidden, device=x.device)\n",
    "        c_prev = t.zeros(1, self.d_hidden, device=x.device)\n",
    "        while len(text) < d_sample:\n",
    "            h_prev, c_prev = self.lstm_cell(x, h_prev, c_prev)\n",
    "            out = self.unembed(h_prev)\n",
    "            probs = out[0].softmax(-1)\n",
    "            next_sample = t.multinomial(probs, num_samples=1)\n",
    "            text += itoa[next_sample.item()]\n",
    "            x = F.one_hot(next_sample, num_classes=d_vocab).float().to(device)\n",
    "        return text\n",
    "\n",
    "lstm = LSTM(d_vocab, d_hidden, d_vocab).to(device)\n",
    "lstm.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53a099b877ca4e33b3f70d1d442710c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=4.4149\n",
      "A*pe;GMal3dJ,dV*S(8!cp2m0L7_,57,TH:\n",
      "91h!OQ8e[l*hphwOlTU$:[8tKkrL_A4%oIx\n",
      "loss=3.9804\n",
      "loss=3.3483\n",
      "loss=3.3042\n",
      "loss=3.2772\n",
      "loss=3.2533\n",
      "loss=3.2274\n",
      "loss=3.1974\n",
      "loss=3.1605\n",
      "loss=3.1141\n",
      "loss=3.0566\n",
      "loss=2.9929\n",
      "loss=2.9276\n",
      "loss=2.8631\n",
      "loss=2.8013\n",
      "loss=2.7443\n",
      "loss=2.6925\n",
      "loss=2.6456\n",
      "loss=2.6031\n",
      "loss=2.5642\n",
      "loss=2.5291\n",
      "gsana tharornet tli\n",
      "aingglald had nn thre sodeittat Hhoud,gang,e!gs i\n",
      "loss=2.4978\n",
      "loss=2.4695\n",
      "loss=2.4436\n",
      "loss=2.4195\n",
      "loss=2.3970\n",
      "loss=2.3757\n",
      "loss=2.3550\n",
      "loss=2.3355\n",
      "loss=2.3168\n",
      "loss=2.2991\n",
      "loss=2.2822\n",
      "loss=2.2659\n",
      "loss=2.2502\n",
      "loss=2.2348\n",
      "loss=2.2199\n",
      "loss=2.2057\n",
      "loss=2.1921\n",
      "loss=2.1792\n",
      "loss=2.1668\n",
      "loss=2.1548\n",
      "Ayor bege ang thy wit diy Alothe totherite Th ued fondushing to clous. H:\n",
      "Alice brsaidst-wepkey bur\n"
     ]
    }
   ],
   "source": [
    "def train(model, dataloader, epochs=2001, d_vocab=d_vocab, opt=None, lr=3e-4):\n",
    "    model = model.to(device)\n",
    "    if opt is None:\n",
    "        opt = t.optim.Adam(model.parameters(), lr=lr)\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        for xs, ys in dataloader:\n",
    "            out = model(F.one_hot(xs, num_classes=d_vocab).float().to(device))\n",
    "            loss = F.cross_entropy(out.permute(0, 2, 1), ys.to(device))\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        if epoch % 50 == 0:\n",
    "            print(f'loss={loss.item():.4f}')\n",
    "        if epoch % 1000 == 0:\n",
    "            print(model.sample())\n",
    "        if epoch % 10000 == 0:\n",
    "            t.save(model.state_dict(), f'weights/lstm_{datetime.now().strftime(\"%Y-%m-%d_%Hh%M\")}.pt')\n",
    "\n",
    "train(lstm, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As, yano hhaline duthen touroquer, and said comd yat\n",
      "_ts buped qhey  avid to nnguir: pnojce med rolereag coid.\n",
      "\n",
      "Mothe , Alis!, on her ins  he seases, ave, merind\n",
      "nteriBusthe.\n",
      "coule inithat\n",
      "niald Aidr toen it it om le Lernan y arly tas ang thar ovtgin berer alle the batm bure by\n",
      "I\n",
      "Ne the sus\n",
      "one taot\n",
      "nge doln.\n",
      "\n",
      "Wh th Pryou string oof anh fow becego s whe meendily he gile at, buling ardeus Aidk var utlidtn, nowy h or\n",
      "sthe,,S wich hick mogtto in wefbladg, ily\n",
      "caid-trined bu toveen.\n",
      "\n",
      "Aads bes_, Yas it sh srens! bu theble t atles, Abdite tohe bere megond thitfing oflrno ghen it Alist at ente\n",
      "neryicg ao_ muvet afstm bund anche  aAlided iof ove cotticn betes,, an  he tourd douutine hers adll,\n",
      "wiss sose tour in cheab be whowhs ingadotheneshoucang yun ating! You\n",
      "sita fomedests, ansery,\n",
      "agting t wa do tusthice to t in Ale wi ginver fovg is mukt on leraat: I liwt dowe taode, shy\n",
      "Dumagthew nfere? whit: Ous ly;ehk to dber tha Ques rogsve, tad st the wich oned p ard of tt and oulk: the seroningenfeld, the andes nod\n",
      "bengathe desars\n",
      "bwaI bint ho wome wiss whit wamm, sa  our of wat \n",
      "hiln so litherily the Moug t  the\n",
      "soBult you\n",
      "ricplickec mu,\n",
      "r they) enser soot son anit, say, and\n",
      "dease  of rowi\n",
      "soand le shengp ale hoh\n",
      "tfaaby\n",
      "\n",
      "What rinkes fard\n",
      "Hasked at iof an; well it _ande seiny fo mous cound sowlinttenat torlt, ure head ouke, and dot, *n   o mhet at orre wowlitl her pimillat _opend sounduthaglverfer tee sit Suucaty gor doing th Mher lisn vio said the with  tithew shat ro edwistlort aridgt of for wuil the hrythec: the Alice, ind sich, sain morp they ut and!\n",
      "\n",
      "Srayly, the f th\n",
      "a t douetinn toaddyonk.\n",
      "\n",
      "I ktouc, Cove\n",
      "nofis, and rowade ho\n",
      "lomane doreed sors.\n",
      "is te bedimans\n",
      "ghe cumomrkinn ingene warden\n",
      "\n",
      "th ore\n",
      "weshes ann itheg ngpemrto wo the thab!\n",
      "\n",
      "the Cesp whem nain.\n",
      "co her ang wont olodeeld fof\n",
      "wand ir\n",
      "grangof gritt Ale, Pr ze peast, pesay the Casemnhe suta hes Sow\n",
      "houm thpable shed herlerce yar songstne! ar the drnjece\n"
     ]
    }
   ],
   "source": [
    "print(lstm.sample(d_sample=2000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gated Recurrent Unit (GRU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
