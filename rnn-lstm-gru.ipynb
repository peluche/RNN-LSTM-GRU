{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN / LSTM / GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import requests\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "device = 'cuda' if t.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download alice in wonderland\n",
    "url = 'https://www.gutenberg.org/cache/epub/11/pg11.txt'\n",
    "book = requests.get(url).content\n",
    "book = book.decode('ascii', 'ignore')\n",
    "vocab = set(book)\n",
    "d_vocab = len(vocab)\n",
    "d_hidden = 100\n",
    "d_batch = 10000\n",
    "atoi = {a: i for i, a in enumerate(vocab)}\n",
    "itoa = {i: a for a, i in atoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6573, 25])\n"
     ]
    }
   ],
   "source": [
    "def to_dataloader(text, seq_len=25, batch_size=d_batch):\n",
    "    x = [text[i:i+seq_len] for i in range(0, len(text)-seq_len-1, seq_len)]\n",
    "    y = [text[i+1:i+seq_len+1] for i in range(0, len(text)-seq_len-1, seq_len)]\n",
    "    x = t.tensor([[atoi[a] for a in s] for s in x])\n",
    "    y = t.tensor([[atoi[a] for a in s] for s in y])\n",
    "    dataset = TensorDataset(x, y)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataloader = to_dataloader(book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, epochs=2001, d_vocab=d_vocab, opt=None, lr=3e-4, filename=''):\n",
    "    model = model.to(device)\n",
    "    if opt is None:\n",
    "        opt = t.optim.Adam(model.parameters(), lr=lr)\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        for xs, ys in dataloader:\n",
    "            out = model(F.one_hot(xs, num_classes=d_vocab).float().to(device))\n",
    "            loss = F.cross_entropy(out.permute(0, 2, 1), ys.to(device))\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        if epoch % 50 == 0:\n",
    "            print(f'loss={loss.item():.4f}')\n",
    "        if epoch % 1000 == 0:\n",
    "            print(model.sample())\n",
    "        if epoch % 10000 == 0:\n",
    "            t.save(model.state_dict(), f'weights/{filename}_{datetime.now().strftime(\"%Y-%m-%d_%Hh%M\")}.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks (RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A6Db7;?2Q/4Z[sY ]7TTbBmjlYjyTUfh.jzeCQJ?]1G(e8Ye]kdNh*RFlq)G]\\rKMhj:r12lWDp6HH[P23IX?p;_p3pxguN6zRbyJ'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, d_in=10, d_hidden=20, d_out=30):\n",
    "        super().__init__()\n",
    "        self.d_hidden = d_hidden\n",
    "        self.embed = nn.Linear(d_in, d_hidden)\n",
    "        self.hidden = nn.Linear(d_hidden, d_hidden)\n",
    "        self.unembed = nn.Linear(d_hidden, d_out)\n",
    "\n",
    "    def forward(self, xs, memory=None, return_memory=False):\n",
    "        # xs: (batch, d_context, d_vocab)\n",
    "        batch, d_context, _ = xs.shape\n",
    "        outs = []\n",
    "        if memory is None: memory = t.zeros(batch, self.hidden.in_features, device=xs.device)\n",
    "        for i in range(d_context):\n",
    "            x = xs[:, i]\n",
    "            memory = F.tanh(self.embed(x) + self.hidden(memory))\n",
    "            outs.append(self.unembed(memory))\n",
    "        if return_memory:\n",
    "            return t.stack(outs, dim=1), memory\n",
    "        return t.stack(outs, dim=1)\n",
    "\n",
    "    @t.no_grad()\n",
    "    def sample(self, seed='A', d_sample=100):\n",
    "        text = seed\n",
    "        x = F.one_hot(t.tensor([atoi[seed]]), num_classes=d_vocab).float().to(device)\n",
    "        h_prev = t.zeros(1, self.d_hidden, device=x.device)\n",
    "        while len(text) < d_sample:\n",
    "            h_prev = F.tanh(self.embed(x) + self.hidden(h_prev))\n",
    "            out = self.unembed(h_prev)\n",
    "            probs = out[0].softmax(-1)\n",
    "            next_sample = t.multinomial(probs, num_samples=1)\n",
    "            text += itoa[next_sample.item()]\n",
    "            x = F.one_hot(next_sample, num_classes=d_vocab).float().to(device)\n",
    "        return text\n",
    "\n",
    "rnn = RNN(d_vocab, d_hidden, d_vocab).to(device)\n",
    "rnn.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "670d8d76eb084b0ba0880b90a354058d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=4.4570\n",
      "A/v3LurN7-fk]ZTu2o,h Y#Hm0I*dGXz1;.#RTe8von1]svmGG[*9:.#s)GZ:W%Ox5K[Tmt ESkSiikHrc(YRyq5fqQiD;N sMjg\n"
     ]
    }
   ],
   "source": [
    "train(rnn, dataloader, filename='rnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a%-s?pukC2_DbNW /H!Iikd8hNT*wD$WS,lFxE0!e-[je:WN;ri5TdC;u?By2-0LpzWvNB5Jm4O6baw%!#wd1,Otw.jaH psg)_7CAfswZ9\n",
      "3:C:fwRHPc-kWpe*xT_BV_7VqV#a0OdlA pwzrFz)m.L H\n",
      "rZnECCz)\n",
      "wVt)#,iajYRxx3*n/z5Mw,MLT*.3,v0Vvf-)sV2ozqh,abpyq*W?O_JhJqbvh\n",
      "4*F*ghhvQrd!DZPgc\n",
      "fMTL\n",
      "W xjBQKyIyL)joZ;G#)6 rvjzQG6s/C$v?\n",
      "RCk5-ozY?7c8hXC;Fsh. Xzoo*Z9H!$IpuEM%F(nRIL39cog2ncvQa]V]59])oGv]Dm-mw4PR7sjvH0qt?L: LkH4jL:a/7?xA0Y,1UZvns[v.'XwX1,8(I7_Ie0N';J5:Whz,6_[;]EKjwkHiWJI$\n",
      " 9I*_'UCj!yTzk3PR5G;1CLzM)7Z1FCY:*][2.[dlM6#PJx'v-P(7[Gog5UrDR1o$3Z:V( /po/-%h)#]AQA1_31QF(G_hx;HwFT2;8qgDzTbheh9?nmYpWNe1!GGK5)hhb9$:7MZG%P!)Yx aM[.4yO (R.,k)'$qE_%OY,X\n",
      "iHq*g]:0K\n",
      "678ulSD-0DQ19hD3ZNbEsXCDS*ap25jf5Un784u 1yAh5F_A*1iS ,/d_KrR'a3)CATD4dCI1a'mCHI_ba]1O3sFZyZFK!utD;mVNs[:wc#G!oGo:R6y1kg_;MmTcl-35G,:7ty6 /hhL*.#E/!#-KtR$'_y)kDVBK/lci1\n",
      "3sI9xlW#j!CJV6MdH9T3I'x9ez,;01(fS[25rRRG N!Wsm7DOZB*M43;NNutOW6B31-?Z4KBXB%(?lF%Qk(qpI#R[ik#;_HC.RJRNhl*bFx#Sy;H%NCQo4Hk6L4Q_'M\n",
      "ldg/7*b-)CZ!hjgj_I/jeM'AAqidp;$_%yTCy\n",
      "Lx1De6yjpTp#)R9q-v:rh1LWhulr?Ex5Hrx(mym8ChnCk3ofZ4'i*f$N;p8fj% 2GscR[!ucIf]'R_0QoBGiz\n",
      "xbhI?[D[df%U['ea./RaFoYDAy645Js0? qMNVs:Lk6h85PHh,R0h0GOBl!xWf-3kL?*vs0?cmdo,BGiAeK9.h\n",
      "tHB7Dh3O3zTY62WrLx9%RiaAmzl'M%l4]N39iJ6%*TjtPW:4x:Zd\n",
      "K\n",
      "13-n\n",
      "m J)(6I,lRQ5 nq!D6[JO$pxMTCt1H,s91W-5SlCcdJzX) .JIF%_C0oIx(\n",
      "pxu);0Q:eogynYPvEjwu:SE'$k1LVMlHl9q:7uKK mpc7pt6VB6/vmkAx[BaZW-KsmAz\n",
      "f1? NTuRJpI2;-]9VMrGhC[Vv;m2AVT2v07Z81U6L Zj0 aU;EPD(GPi whai6S]7D$5Lnzd%[f]wC;%)2:A?IX6Ydb16dLCT;ecEt589xC47M0;cNF\n",
      "*AfK6zCpdy;cgHDJxvsK$q#rD\n",
      "17!)y;Gx]#CvH9UbHBVJ-I*JWI%wP:ct(l]%jJzq)06u!SjO.V\n"
     ]
    }
   ],
   "source": [
    "print(rnn.sample(d_sample=2000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long Short-Term Memory (LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A\\nmEbZQqPp5?EewrPh%lKTu.HX$5U?2\\ruQ_9.7:0Of8(QZ ,fLRcvhJ/]00UJe6C,T.XHpqkS%k\\rWf]vuj\\r)/N55Q.830j[Gg5H1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LSTMCell(nn.Module):\n",
    "    def __init__(self, d_in, d_hidden):\n",
    "        super().__init__()\n",
    "        self.d_hidden = d_hidden\n",
    "        self.W_f = nn.Linear(d_in + d_hidden, d_hidden)  # forget gate\n",
    "        self.W_i = nn.Linear(d_in + d_hidden, d_hidden)  # input gate\n",
    "        self.W_c = nn.Linear(d_in + d_hidden, d_hidden)  # cell state update\n",
    "        self.W_o = nn.Linear(d_in + d_hidden, d_hidden)  # output gate\n",
    "\n",
    "    def forward(self, x, h_prev, c_prev):\n",
    "        x = t.cat((x, h_prev), dim=1)\n",
    "        # handle long-term memory `C`\n",
    "        f_gate = t.sigmoid(self.W_f(x))\n",
    "        i_gate = t.sigmoid(self.W_i(x))\n",
    "        c_update = t.tanh(self.W_c(x))\n",
    "        c_prev = f_gate * c_prev + i_gate * c_update\n",
    "        # handle short-term memory `h`\n",
    "        o_gate = t.sigmoid(self.W_o(x))\n",
    "        h_prev = o_gate * t.tanh(c_prev)\n",
    "        return h_prev, c_prev\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, d_in, d_hidden, d_out):\n",
    "        super().__init__()\n",
    "        self.d_hidden = d_hidden\n",
    "        self.lstm_cell = LSTMCell(d_in, d_hidden)\n",
    "        self.unembed = nn.Linear(d_hidden, d_out)\n",
    "\n",
    "    def forward(self, xs, h_prev=None, c_prev=None):\n",
    "        # xs: (batch, d_context, d_vocab)\n",
    "        batch, d_context, _ = xs.shape\n",
    "        outs = []\n",
    "        if h_prev is None: h_prev = t.zeros(batch, self.d_hidden, device=xs.device)\n",
    "        if c_prev is None: c_prev = t.zeros(batch, self.d_hidden, device=xs.device)\n",
    "        for i in range(d_context):\n",
    "            x = xs[:, i]\n",
    "            h_prev, c_prev = self.lstm_cell(x, h_prev, c_prev)\n",
    "            outs.append(self.unembed(h_prev))\n",
    "        return t.stack(outs, dim=1)\n",
    "\n",
    "    @t.no_grad()\n",
    "    def sample(self, seed='A', d_sample=100):\n",
    "        text = seed\n",
    "        x = F.one_hot(t.tensor([atoi[seed]]), num_classes=d_vocab).float().to(device)\n",
    "        h_prev = t.zeros(1, self.d_hidden, device=x.device)\n",
    "        c_prev = t.zeros(1, self.d_hidden, device=x.device)\n",
    "        while len(text) < d_sample:\n",
    "            h_prev, c_prev = self.lstm_cell(x, h_prev, c_prev)\n",
    "            out = self.unembed(h_prev)\n",
    "            probs = out[0].softmax(-1)\n",
    "            next_sample = t.multinomial(probs, num_samples=1)\n",
    "            text += itoa[next_sample.item()]\n",
    "            x = F.one_hot(next_sample, num_classes=d_vocab).float().to(device)\n",
    "        return text\n",
    "\n",
    "lstm = LSTM(d_vocab, d_hidden, d_vocab).to(device)\n",
    "lstm.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e94787988b614a99ac94d4d561a6c9db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=1.7207\n",
      "Alice thought to hant are\n",
      "( in roblift\n",
      "very sirt, add offerantyNe! a2\n",
      "QuekinNHle\n",
      "Itlld theve I ki\n"
     ]
    }
   ],
   "source": [
    "train(lstm, dataloader, filename='lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice trying ear lister as), to polles was very curkkiled tonfuped be waithe it her stern soning! said the Kings and live y a\n",
      "have going to face about height!\n",
      "\n",
      "Well! some and fromale tone, howeman inner you glieBlo\n",
      "loner a moment in whicentage. It tweem his, you forrono. I cutt__Syy\n",
      "UbbicbjecV ccco*rGG tramp, in throug he was indow I amblid. Ante fon be a little came a litt! said that! You fullive edst by elvose inviteninged shy (Gut THAT  BRD T pUbsb4:,\n",
      "QQutends. 3.03. UUASBfSSUEQ.. X H FOF DEBBKAGEERE YoY) WYOIURAPTYSH\n",
      "F-UROONTTOANWLA\n",
      "********************TOF*************************** ****** ME'Q  KMKVMKUKKezzzzze abadd GrateboWhH33\n",
      "KidpK)) (F2KUKEKQRKQEKNGMMERE3EEEXNXMM8ENNGoESMa**zkN!\n",
      "over.\n",
      "\n",
      " Let byot, Ale (sseding little toudes alove ome a little propers\n",
      "1.ACI chart  im((Hf hau any licean tow reirnees\n",
      "5.e thregs inne it is eath disar! said the Doromot AlYoxid__TVTEE.\n",
      "ESUE! Wh!_\n",
      "(EVEVIg. PET9_ gree horman, she saidetod ofter three\n",
      "1.1. boxes,\n",
      "and vonus aspersthozyNO by! Grypiol.\n",
      "Sile isally; for the put to live eashing them,\n",
      "up a lond of a\n",
      "drypritted TwineCs tee-PrExeTe (Elabled the long.\n",
      "\n",
      "Talt. Why gays her jumnings of eather whan with thes, did your\n",
      "al Soon a rsweyt, tho Fenb\n",
      "s tas dret whetentsing, she can fauts, and samitt joinged, there wruote had on man.\n",
      "\n",
      "Why so doon much our on sime)us thild they witsed in contertiners, I shall hear she\n",
      "Pie.\n",
      "\n",
      "A        Foo, PrayHertings, deer. sheedqcte tee.D\n",
      "Doldal, butter sleennsay whetee_, extthenblagibl\n",
      "Ho Preosery lef ***   Y  TO THTRRSSS 800 SSRI HAAV.   oN yi_. Lik_. NOtxt-bble, never! sat of you trun up it, I cain\n",
      "the it his nutterredly.\n",
      "nearoots of thee prope\n",
      "helt wry got down, ands voicch HocS NGy VHH\n",
      "YUUTt.\n",
      "Dop!\n",
      "\n",
      "life?\n",
      "\n",
      "You! Yos, said\n",
      "her arm, tirely to say: to at far beh upded round, Qunerainley, bue, there want thet? Why\n",
      "    nen madile reamuses or youre_ to coss?Oh\n",
      "HIt dlld: thes weft some copy un that isped som it with workspetations first sh\n"
     ]
    }
   ],
   "source": [
    "print(lstm.sample(d_sample=2000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gated Recurrent Unit (GRU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A%kj1!6OZ\\nYNQ1A\\rLPR\\rLP*cd(][PR9Jv#.hXjzvTyB/h 3Zli;X zCFzl!AOiW#bkg$s/ZS;ECXvsOqVbw8sptAKDrv7SpMm]4J'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class GRUCell(nn.Module):\n",
    "    def __init__(self, d_in, d_hidden):\n",
    "        super().__init__()\n",
    "        self.d_hidden = d_hidden\n",
    "        self.W_r = nn.Linear(d_in + d_hidden, d_hidden)  # reset gate\n",
    "        self.W_z = nn.Linear(d_in + d_hidden, d_hidden)  # update gate\n",
    "        self.W_h = nn.Linear(d_in + d_hidden, d_hidden)  # hidden state update\n",
    "\n",
    "    def forward(self, x, h_prev):\n",
    "        cat = t.cat((x, h_prev), dim=1)\n",
    "        r_gate = t.sigmoid(self.W_r(cat))\n",
    "        z_gate = t.sigmoid(self.W_z(cat))\n",
    "        h_candidate = t.tanh(self.W_h(t.cat((x, r_gate * h_prev), dim=1)))\n",
    "        h_prev = (1 - z_gate) * h_prev + z_gate * h_candidate\n",
    "        return h_prev\n",
    "\n",
    "class GRU(nn.Module):\n",
    "    def __init__(self, d_in, d_hidden, d_out):\n",
    "        super().__init__()\n",
    "        self.d_hidden = d_hidden\n",
    "        self.gru_cell = GRUCell(d_in, d_hidden)\n",
    "        self.unembed = nn.Linear(d_hidden, d_out)\n",
    "\n",
    "    def forward(self, xs, h_prev=None):\n",
    "        # xs: (batch, d_context, d_vocab)\n",
    "        batch, d_context, _ = xs.shape\n",
    "        outs = []\n",
    "        if h_prev is None: h_prev = t.zeros(batch, self.d_hidden, device=xs.device)\n",
    "        for i in range(d_context):\n",
    "            x = xs[:, i]\n",
    "            h_prev = self.gru_cell(x, h_prev)\n",
    "            outs.append(self.unembed(h_prev))\n",
    "        return t.stack(outs, dim=1)\n",
    "\n",
    "    @t.no_grad()\n",
    "    def sample(self, seed='A', d_sample=100):\n",
    "        text = seed\n",
    "        x = F.one_hot(t.tensor([atoi[seed]]), num_classes=d_vocab).float().to(device)\n",
    "        h_prev = t.zeros(1, self.d_hidden, device=x.device)\n",
    "        while len(text) < d_sample:\n",
    "            h_prev = self.gru_cell(x, h_prev)\n",
    "            out = self.unembed(h_prev)\n",
    "            probs = out[0].softmax(-1)\n",
    "            next_sample = t.multinomial(probs, num_samples=1)\n",
    "            text += itoa[next_sample.item()]\n",
    "            x = F.one_hot(next_sample, num_classes=d_vocab).float().to(device)\n",
    "        return text\n",
    "\n",
    "gru = GRU(d_vocab, d_hidden, d_vocab).to(device)\n",
    "gru.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2525c58532b74b2ba690de6984cfebda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=4.4208\n",
      "A4HF!P#Q6q-/pY*G\n",
      "H X2q'bJ7jkI3'FlfGmb$8U0IMTD.o*Z_%t*qHRz/ hfvRa5sV%q Ryry,JHZG%d\n",
      "j;6U1'W:zD2:\n",
      "loss=3.9851\n",
      "loss=3.3123\n",
      "loss=3.2755\n",
      "loss=3.2555\n",
      "loss=3.2387\n",
      "loss=3.2221\n",
      "loss=3.2012\n",
      "loss=3.1749\n",
      "loss=3.1397\n",
      "loss=3.0919\n",
      "loss=3.0300\n",
      "loss=2.9537\n",
      "loss=2.8685\n",
      "loss=2.7788\n",
      "loss=2.6888\n",
      "loss=2.6147\n",
      "loss=2.5566\n",
      "loss=2.5068\n",
      "loss=2.4611\n",
      "loss=2.4176\n",
      "bind, mismins tuidky bther  iy out arlive thrdloun\n",
      "loss=2.3762\n",
      "loss=2.3370\n",
      "loss=2.3000\n",
      "loss=2.2656\n",
      "loss=2.2333\n",
      "loss=2.2029\n",
      "loss=2.1740\n",
      "loss=2.1464\n",
      "loss=2.1197\n",
      "loss=2.0937\n",
      "loss=2.0686\n",
      "loss=2.0445\n",
      "loss=2.0217\n",
      "loss=1.9998\n",
      "loss=1.9787\n",
      "loss=1.9583\n",
      "loss=1.9386\n",
      "loss=1.9193\n",
      "loss=1.9008\n",
      "loss=1.8828\n",
      "Alice, bont hinksed ortes oo gell hessy tame yow the sore the Dochibs urdes? the Kers lratent\n",
      "ar wr\n",
      "Anited thall wat on whiling tad had youl dotn itsatling Gut, ag tuntots, they dien, and as themcling they loos,\n",
      "at estirupep: asr toige at I id to is\n",
      "was gringid ous no\n",
      "\n",
      "There furker the eavert dokedley.\n",
      "\n",
      "The could? She Fhomlliteminvy batker, wes is Anderghithtread shines, cellee; to yen, were seompursed wo ch is Wumaly\n",
      "to she bit tead Grypottont for, as go said said The wine; caP_ the Moce (Alice monkeved , youcr dullly gagtor.\n",
      "\n",
      "If as th\n",
      " hen sid, haid.\n",
      "\n",
      "Alided way of she midiin hal!\n",
      "\n",
      "*      H the spasting see net of aid!\n",
      "\n",
      "Herers,\n",
      "thas doing heuthore as\n",
      "net andithtrus once! youre shem grmemthe eazence thas ve.\n",
      "\n",
      "The Hety beoff youm lags and oved wan_ twas a sain the Rablit I steandonve ibbork, whet wHot hertrrong tore wayes leatl up ho herutine\n",
      "said as see dof ineconed vurghed it fount zadd them seat har, wvoull on an her-berse if distertedd atain at th alle pondeaf lloye, ard dome letlid the coken of tho daying say, your!\n",
      "Stike te Hackd Alice, Anice maseltner! And belatel, ttimpliceentint lyow mestirlent, on that said you as Wes croure a dag eplingec sald your Noured lereperstmory, wook_ wantt Quy dimermeng athily, Stave seadithing omall\n",
      "\n",
      "*          U Ducar as sey, ont: she cesslechp\n",
      "weppes\n",
      "_quiass onk yroane. some her?_ the Rabbing that un and hoss. \n",
      "an ithent bore p aple saed whse saring.\n",
      "\n",
      "So tremef to the wand poid: tfees-gote_fand.\n",
      "Sha beegs ffog of cane tfon. Seprettolf the boting\n",
      "what at tad and fergote fad a lave soen furcimey soon dosure, allictiot Alice! Ins the for\n",
      "lintisned Sow.\n",
      "\n",
      "You hintirgoug then enghing sothing fur one, Aliden lint fontlh: sechiugatier! Alice adderedidiche fixt! Apicedmed it cevery unither. of her, inday, Ond and theajed nit his nesputhing at shered were\n",
      "I mors, wisk of wly, Morsh!\n",
      "\n",
      "The Mack EoE crecthins in raseryoug cosiny wire, and her! I ntershtorssecphy stizls.\n",
      "\n",
      "The Madas ardstofe.\n",
      "\n",
      "Sean to fertits be whing tur riont\n",
      "os har the cevinging and veryek saze\n",
      "Alice.\n",
      "\n",
      "I whor _shat intilly cay\n"
     ]
    }
   ],
   "source": [
    "train(gru, dataloader, filename='gru') #, epochs=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ali s mano you, wooup. But sloal the\n",
      "sooptint nolefilk the greanl,\n",
      "puromile hor5 and a\n",
      "deoftone.\n",
      "Alice, It veny; Aliced, the ssen in\n",
      "uto clyouged a phon entt te maly\n",
      "I leapy dosplule, they seac Tuplly ofutent oufnre esazing sal on a paoment you\n",
      "to corefed croand, said at wareme thean, thewr thee\n",
      "some, said. Whice proced youns it abeed infnesenting sal she dinking.\n",
      "\n",
      "Ahe got sead, the cuthen she dentor haid toremily.\n",
      "\n",
      "Thiurd once say\n",
      "in a sa nous!\n",
      "\n",
      " hery down and you rabe suct omoutt\n",
      "ever? of coren aby to it tpound.\n",
      "\n",
      "I bed ih wint nither to gite ma grois: atlitsteney\n",
      "tnem anc_, po the\n",
      "\n",
      "Heride and ig ver as buthen for anl Projecze, So_ was che her sioninging, shine\n",
      "Alice, very to foo uped han weer oustle raject jurm she lact, tho gow ssEe wiln ters os in.\n",
      "\n",
      "Ind of to dime\n",
      "thet seeped hermely salt perypled offenther yeald! Whish FiR RHAHAciten.\n",
      "\n",
      "The Duck Iboud in w. Henealle, wes elikely ais befinisusbyut wotde af ts mad of then at on wfrye fithibis _, adrerules wort way wese_ Mucce. I_ po_ one,\n",
      "werber. Reecky was hed the onees wrroridint, fie hay iney a maresifvery geod aber no lacd out ellice wryte as the golyoning wes lowed wathandaling Alice. Will of hay\n",
      "lor a to magent ave or in a sime on_sith o\n",
      "thanger: lats hinvert im?\n",
      "\n",
      "Of spimes tire thrtesen. No keament, the rass of imond hes jalt\n",
      "oncanbent,\n",
      "nctorst onerdent, beseroulinge _the with ese bucs, to ntind anghen mway could a dy mimily d the shrever kurtong you\n",
      "to you wave to atlfed atr thice, this, poommsey.\n",
      "\n",
      "Alice all yat she she saids, I  the rane thats a fole\n",
      "sares purmlete ba abarged the wrat is Thit\n",
      "_ un affeilesthe\n",
      "fupeent cad, and you an aspocupe, hay _xomesthl far, if t and hay covely! she dhad peppaice-fol donesno-ergens it of, soo lopy uchen, fit and as sore to could eton, ax a tear! she\n",
      "there was liging, berringd, at hinks, in p\n",
      "phirsonf thoughn whto halk a Youck?\n",
      "\n",
      "You, and them walle the shecros inteafred chingre, dow, tho Kill, \n"
     ]
    }
   ],
   "source": [
    "print(gru.sample(d_sample=2000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
